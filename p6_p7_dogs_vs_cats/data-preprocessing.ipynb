{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs Vs Cats:  Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络（Convolutional Neural Network, CNN）\n",
    "\n",
    "## 项目：猫狗大战\n",
    "\n",
    "### 项目内容\n",
    "\n",
    "本项目拟采用 keras 结合 tensorflow 作为后端来完成编码。具体流程如下：\n",
    "\n",
    "* [Step 0](#step0): 数据预处理\n",
    "* [Step 1](#step1): 搭建模型\n",
    "* [Step 2](#step2): 模型训练\n",
    "* [Step 3](#step3): 模型评估\n",
    "* [Step 4](#step4): 模型可视化\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## 步骤 0: 数据预处理\n",
    "\n",
    "#### 数据集探索\n",
    "首先从 Kaggle 网站下载本项目所需的训练集文件 train.zip 和测试集文件 test.zip，分别解压放置于 data 目录下。检索发现测试集中的图片文件名按猫狗分别附加有 \"dog\" 或者 \"cat\" 前缀。为了使用 sklearn.datasets.load_files 工具，将测试集的图片按猫和狗分为两个目录存储，最终目录层级组织如下：\n",
    "\n",
    "```\n",
    "data  \n",
    "├── test  \n",
    "│   ├── 1.jpg  \n",
    "│   ├── 2.jpg  \n",
    "│   ├── .....  \n",
    "│   └── 12500.jpg  \n",
    "└── train  \n",
    "    ├── cat  \n",
    "    │   ├── cat.0.jpg  \n",
    "    │   ├── cat.1.jpg  \n",
    "    │   ├── ......  \n",
    "    │   └── cat.12500.jpg  \n",
    "    └── dog  \n",
    "        ├── dog.0.jpg  \n",
    "        ├── dog.1.jpg  \n",
    "        ├── ......  \n",
    "        └── dog.12500.jpg  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from keras.applications import Xception\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# define function to load train dataset\n",
    "def load_train_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return files, targets\n",
    "\n",
    "# load train dataset\n",
    "train_files, train_targets = load_train_dataset('data/train')\n",
    "train_dogs = [path for path in train_files if 'dog' in path]\n",
    "train_cats = [path for path in train_files if 'cat' in path]\n",
    "\n",
    "# load test dataset\n",
    "test_files = os.listdir('data/test')\n",
    "\n",
    "# print statistics about the datasets\n",
    "print(\"There are {} training images, include {} dogs images and {} cats images.\"\n",
    "      .format(len(train_files), len(train_dogs), len(train_cats)))\n",
    "print(\"There are {} testing images.\".format(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图片尺寸范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_shapes = np.array([cv2.imread(file, 0).shape for file in train_files])\n",
    "train_image_sizes  = np.array([shape[0] * shape[1] for shape in train_image_shapes])\n",
    "\n",
    "print(\"The range of training images width is [{}, {}]\"\n",
    "      .format(min(train_image_shapes[:,0]), max(train_image_shapes[:,0])))\n",
    "print(\"The range of training images height is [{}, {}]\"\n",
    "      .format(min(train_image_shapes[:,1]), max(train_image_shapes[:,1])))\n",
    "print(\"The range of training imagse area(width*height) is [{}, {}]\"\n",
    "      .format(min(train_image_sizes), max(train_image_sizes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 绘制图片尺寸分布图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot image height, width, area distribution\n",
    "plt.subplot(221)\n",
    "plt.hist(train_image_shapes[:,0], alpha=0.5, color=['green'])\n",
    "plt.title('Image width distribution')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(train_image_shapes[:,1], alpha=0.5, color=['green'])\n",
    "plt.title('Image height distribution')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(train_image_sizes, alpha=0.8, color=['green'])\n",
    "plt.title('Image area distribution')\n",
    "\n",
    "# 调整子图间距\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片预处理\n",
    "\n",
    "1. 图片编码处理，转换为灰度图\n",
    "2. 图片大小调整，缩放至适当大小\n",
    "3. 随机对图片进行翻转、色彩处理\n",
    "4. 将训练集分割为训练集和验证集\n",
    "\n",
    "使用 opencv 结合 ImageDataGenerator 工具进行图片预处理。首先将图片 resized 到 299x299大小，然后对对图像实现归一化处理，将每张图像的像素值除以255，缩放到 0～1 之间。随后进行数据增强：随机左右、上下机旋转翻转，随机旋转一定角度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "target_image_size = (256, 256)\n",
    "batch_size = 25\n",
    "\n",
    "X = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), #立方差值\n",
    "                         target_image_size,\n",
    "                         interpolation=cv2.INTER_CUBIC)\n",
    "              for path in train_files])\n",
    "#Y = np.array([0 if 'dog' in path else 1 for path in train_files])\n",
    "Y = train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集\n",
    "\n",
    "目标：将初始训练集按照 3:1:1 的比例拆分为训练集、验证集和测试集。\n",
    "1. 首先按 4:1 的比例将测试集拆分成训练集和测试集  \n",
    "2. 再将按 3:1 的比例将训练集拆分为训练集和验证集  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# random_state设置为0, 取保每次分割都一样\n",
    "#X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "X_1, X_test, Y_1, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_1, Y_1, test_size=0.25, random_state=0)\n",
    "\n",
    "print(\"The size of train set: {}, the size of validation set: {}, the size of test set: {}\".\n",
    "      format(len(X_train), len(X_validation), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1.0/255,      #像素值正则化0～1\n",
    "                              rotation_range=45,    #随机旋转角度范围\n",
    "                              horizontal_flip=True, #随机左右翻转\n",
    "                              vertical_flip=True)   #随机上下翻转\n",
    "\n",
    "train_generator = data_gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "validation_generator = data_gen.flow(X_validation, Y_validation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "####  获取模型的特征向量\n",
    "\n",
    "提取 Xception 模型中与训练、测试与验证集相对应的 bottleneck 特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## 步骤1：搭建模型\n",
    "\n",
    "现在使用迁移学习来建立一个CNN，从而可以从图像中区别出猫还是狗。这里选取 Keras 提供的几个预训练的模型中，比较新且参数数量比较小的 Xception 模型作为基础模型，所以选择 Xception 模型和 imagenet 预训练权重进行训练。\n",
    "\n",
    "为了适合本项目猫狗的二分类，将Xception模型的输出层改为二分类的全连接。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = Xception(include_top=False, weights='imagenet')\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "#outputs = Dense(2, activation='softmax')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## 步骤2：训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 编译模型\n",
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型。\n",
    "\n",
    "为防止过拟合，val_loss不再下降后的3个epochs后停止训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 50\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n",
    "CALLBACKS = [earlyStopping]\n",
    "#history = model.fit(x=X_train, y=Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "#                    callbacks=CALLBACKS, validation_data=(X_validation, Y_validation))\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=CALLBACKS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(X_validation) // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## 步骤 3: 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## 步骤4：模型可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献  \n",
    "1. [深度学习——分类之Xception和卷积的分组](https://zhuanlan.zhihu.com/p/32965380)\n",
    "2. [手把手教你如何在Kaggle猫狗大战冲到Top2%](https://zhuanlan.zhihu.com/p/25978105)\n",
    "3. [Keras Image Data Augmentation 各参数详解](https://zhuanlan.zhihu.com/p/30197320)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
